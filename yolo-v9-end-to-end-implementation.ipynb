{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceType":"competition","sourceId":24800,"datasetId":1042002,"databundleVersionId":1831594}],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Loading train_dataframe","metadata":{}},{"cell_type":"code","source":"test_dir = \"/kaggle/input/vinbigdata-chest-xray-abnormalities-detection/test\"\ntrain_dir = \"/kaggle/input/vinbigdata-chest-xray-abnormalities-detection/train\"\ntrain_df = pd.read_csv('/kaggle/input/vinbigdata-chest-xray-abnormalities-detection/train.csv')\ntrain_df.head(2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## mapping image_id to its image_path","metadata":{}},{"cell_type":"code","source":"import glob\nfrom tqdm import tqdm\nimport pandas as pd\n\n# Enable pandas progress_apply\ntqdm.pandas()\n\n# Load the list of training DICOM images\nyy = glob.glob(train_dir + \"/*\")\n\n# Apply progress_apply to create the 'ImagePath' column\ntrain_df['ImagePath'] = train_df['image_id'].progress_apply(lambda x: next(filter(lambda y: x in y, yy), None))\n\n# Filter out the 'No Finding' class (class_id == 14)\ntrain_df = train_df[train_df['class_id'] != 14].reset_index(drop=True)\n\n# Select only required columns\ntrain_df = train_df[['ImagePath', 'image_id', 'class_name', 'class_id', 'rad_id', 'x_min', 'y_min', 'x_max', 'y_max']]\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Analysis of the train_dataframe","metadata":{}},{"cell_type":"code","source":"print(\"No Of The Unique ImagePath :--->\", len(set(train_df['ImagePath'])))\nprint(\"Shape Of The Data Frame :->\", train_df.shape)\ntrain_df.head(2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Function To Convert Diacom To An Image\n#### Creating Train and Validation Directories and Converting the DICOM to Image Array and  Saving It in Train and Validation Directories","metadata":{}},{"cell_type":"code","source":"import os\nimport glob\nimport numpy as np\nimport pydicom\nimport matplotlib.pyplot as plt\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\nimport cv2\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def dicom2array(path, voi_lut=True, fix_monochrome=True):\n    dicom = pydicom.read_file(path)\n    # VOI LUT (if available by DICOM device) is used to\n    # transform raw DICOM data to \"human-friendly\" view\n    if voi_lut:\n        data = apply_voi_lut(dicom.pixel_array, dicom)\n    else:\n        data = dicom.pixel_array\n    # depending on this value, X-ray may look inverted - fix that:\n    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n        data = np.amax(data) - data\n    data = data - np.min(data)\n    data = data / np.max(data)\n    data = (data * 255).astype(np.uint8)\n    return data\n\ndef plot_imgs(imgs, cols=4, size=7, is_rgb=True, title=\"\", cmap='gray', img_size=(500,500)):\n    rows = len(imgs)//cols + 1\n    fig = plt.figure(figsize=(cols*size, rows*size))\n    for i, img in enumerate(imgs):\n        if img_size is not None:\n            img = cv2.resize(img, img_size)\n        fig.add_subplot(rows, cols, i+1)\n        plt.imshow(img, cmap=cmap)\n    plt.suptitle(title)\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dicom_paths =  list(set(train_df['ImagePath']))\nimgs = [dicom2array(path) for path in dicom_paths[:4]]\nplot_imgs(imgs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Maybe, you can try some preprocess like equalize histogram. You can see the difference between before and after","metadata":{}},{"cell_type":"code","source":"from skimage import exposure\nimgs = [exposure.equalize_hist(img) for img in imgs]\nplot_imgs(imgs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Function to save the image in a slower way","metadata":{}},{"cell_type":"code","source":"# def saving_image(output_dir, dicom_path_list = dicom_paths):\n#     for dicom_path in tqdm(dicom_path_list):\n#         file_name = os.path.basename(dicom_path).split('.')[0]\n#         image_array = dicom2array(dicom_path)\n#         equalized_image = exposure.equalize_hist(image_array)\n#         cv2.imwrite(os.path.join(output_dir, f\"{file_name}.jpeg\"), equalized_image)\n\n# # Example usage:\n# output_dir = \"/kaggle/working/chest_detection/Images\"\n# os.makedirs(output_dir, exist_ok=True)\n\n# # Call the function to save images\n# saving_image(output_dir, dicom_paths[:3])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Here we will use MultiThreading to Process and save the image in a faster way ","metadata":{}},{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nimport pydicom\nimport multiprocessing\nfrom tqdm import tqdm\nfrom skimage import exposure\n\ndef dicom2array(path, voi_lut=True, fix_monochrome=True):\n    dicom = pydicom.read_file(path)\n    if voi_lut:\n        data = apply_voi_lut(dicom.pixel_array, dicom)\n    else:\n        data = dicom.pixel_array\n    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n        data = np.amax(data) - data\n    data = data - np.min(data)\n    data = data / np.max(data)\n    data = (data * 255).astype(np.uint8)\n    return data\n\ndef process_image(dicom_path_output_dir):\n    dicom_path, output_dir = dicom_path_output_dir\n    file_name = os.path.splitext(os.path.basename(dicom_path))[0]\n    image_array = dicom2array(dicom_path)\n    equalized_image = exposure.equalize_hist(image_array)\n    equalized_image = (equalized_image * 255).astype(np.uint8)\n    cv2.imwrite(os.path.join(output_dir, f\"{file_name}.jpeg\"), equalized_image)\n\ndef saving_image(output_dir, dicom_path_list):\n    os.makedirs(output_dir, exist_ok=True)\n    dicom_path_output_dir_list = [(path, output_dir) for path in dicom_path_list]\n\n    # Use multiprocessing Pool for parallel processing\n    with multiprocessing.Pool() as pool:\n        list(tqdm(pool.imap(process_image, dicom_path_output_dir_list), total=len(dicom_path_list), desc=\"Processing Images\"))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Now We Will Process The Train Diacom Images","metadata":{}},{"cell_type":"code","source":"# Example usage:\noutput_dir = \"/kaggle/working/chest_detection/images\"\nos.makedirs(output_dir, exist_ok=True)\n\n# Call the function to save images\nsaving_image(output_dir, dicom_paths)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Now We Will Process The Test Diacom Image","metadata":{}},{"cell_type":"code","source":"test_dicom_paths = glob.glob(\"/kaggle/input/vinbigdata-chest-xray-abnormalities-detection/test/*\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Example usage:\noutput_dir = \"/kaggle/working/chest_detection/test\"\nos.makedirs(output_dir, exist_ok=True)\n\n# Call the function to save images\nsaving_image(output_dir, test_dicom_paths)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### now we will visualize the image on the  images directory","metadata":{}},{"cell_type":"code","source":"yy = glob.glob(\"/kaggle/working/chest_detection/images/*\") ## SaveImagePath\narray = cv2.imread(yy[2])\nplt.imshow(array)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Checking Whether The height and width of all image is same or different\n### THis Will Help In Normalizing BoudingBox","metadata":{}},{"cell_type":"code","source":"heights = []\nwidths =  []\n\n# Use list comprehensions for a more concise and efficient code\nheights = [cv2.imread(i).shape[0] for i in tqdm(yy)]\nwidths = [cv2.imread(i).shape[1] for i in tqdm(yy)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Height is \", heights[:3])\nprint(\"width is \", widths[:3])\n\n### As We Can Clearly See That The Height And Width Vary From Image To Image.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Creating Dataframe which will contain the columns SaveImagePath , heights and width","metadata":{}},{"cell_type":"code","source":"### Now Creating Data Frame For The Height ,Width \ndf = pd.DataFrame(yy, columns =['SaveImagePath'])\ndf['image_id'] = df['SaveImagePath'].apply(lambda x: x.split('/')[-1].split('.')[0])\ndf['Height'] = heights\ndf['Width']  = widths\nprint(\"shape Of The Data Frame :->\", df.shape)\ndf.head(1)\n\nprint(\"shape of the train_df\", train_df.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_df  = train_df.merge(df, on = 'image_id')\nfinal_df.head(2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Converting DataFrame to YOLO Format:\n\n#### To prepare bounding box annotations for YOLO object detection, the DataFrame containing bounding box coordinates and class labels needs to be converted to YOLO format. \n\nIn YOLO format, bounding box coordinates are normalized to the range [0, 1], where (x_center, y_center, width, height) are relative to the image dimensions. This normalized format ensures consistency across images of different sizes and aspect ratios.\n","metadata":{}},{"cell_type":"code","source":"def convert_to_yolo_format(df):\n    # Normalize the bounding box coordinates\n    df['center_x'] = (df['x_min'] + df['x_max']) / 2\n    df['center_y'] = (df['y_min'] + df['y_max']) / 2\n    df['b_box_width'] = df['x_max'] - df['x_min']\n    df['b_box_height'] = df['y_max'] - df['y_min']\n    \n    # Calculate normalized coordinates and dimensions\n    df['normalized_x'] = df['center_x'] / df['Width']\n    df['normalized_y'] = df['center_y'] / df['Height']\n    df['normalized_width'] = df['b_box_width'] / df['Width']\n    df['normalized_height'] = df['b_box_height'] / df['Height']\n    \n    return df\n\n### This Function Will Return The DataFrame With Normalize Bounding Box\ndf_yolo = convert_to_yolo_format(final_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_yolo.head(1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Function To Save The Bounding Box","metadata":{}},{"cell_type":"code","source":"def Get_Bounding_Box(df, output_file):\n    # Open the output file for writing\n    with open(output_file, 'w') as f:\n        # Iterate over the filtered DataFrame and write bounding box information to the file\n        for _, row in df.iterrows():\n            class_id = row['class_id']\n            x_center, y_center = row['normalized_x'], row['normalized_y']\n            width, height = row[\"normalized_width\"], row['normalized_height']\n#             print(f\"{class_id}\\t{x_center}\\t{y_center}\\t{width}\\t{height}\\n\")\n            f.write(f\"{class_id}\\t{x_center}\\t{y_center}\\t{width}\\t{height}\\n\")\n\n# Example usage:\nGet_Bounding_Box(df=df_yolo, output_file='test.txt')\n\nImage_label_dir = \"/kaggle/working/chest_detection/labels\"\nos.makedirs(Image_label_dir, exist_ok = True)\n\nprint(\"Storing  Training Image BoundingBox\",\"-\"*50)\nprint(\"Train label dir is \", Image_label_dir)\nfor file in tqdm(yy):\n    filename = file.split('/')[-1].split('.')[0]\n    Get_Bounding_Box(df=df_yolo.head(), output_file = Image_label_dir+\"/\"+filename+\".txt\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Conclusion :- > Finally  We Have store Images and Label in Chest Directory","metadata":{}},{"cell_type":"markdown","source":"#### Lets Check Inside the label directory\n","metadata":{}},{"cell_type":"code","source":"label_files = glob.glob('/kaggle/working/chest_detection/labels/*')\n'/kaggle/working/chest_detection/Images/5184bc9a54adf7c8cb707c45f21fd741.jpeg'\n\nwith open(label_files[0]) as f:\n    file = f.read()\n    print(file)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Lets Check Inside the Image directory","metadata":{}},{"cell_type":"code","source":"image_files = yy[0]\n\narray = cv2.imread(image_files)\nplt.imshow(array)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Bounding Box","metadata":{}},{"cell_type":"markdown","source":"Function: plot_bounding_boxes_on_image\n\nDescription:\nThis function plots bounding boxes on top of an image using the provided bounding box labels and class dictionary.\n\nParameters:\n\nimage_path: Path to the image file.\nbounding_box_label_path: Path to the file containing bounding box labels.\nclass_dict: Dictionary mapping class IDs to class labels. Defaults to an empty dictionary.","metadata":{}},{"cell_type":"code","source":"import cv2\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport random\n\ndef plot_image_with_bounding_box(image, bounding_boxes, class_dict):\n    fig, ax = plt.subplots()\n    ax.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n    \n    for box in bounding_boxes:\n        class_id, x, y, width, height = map(float, box.split())\n        image_width, image_height = image.shape[1], image.shape[0]\n        x1 = int((x - width / 2) * image_width)\n        y1 = int((y - height / 2) * image_height)\n        x2 = int((x + width / 2) * image_width)\n        y2 = int((y + height / 2) * image_height)\n        \n        # Choose random color for bounding box\n        color = [random.random() for _ in range(3)]\n        \n        rect = plt.Rectangle((x1, y1), x2 - x1, y2 - y1, linewidth=2, edgecolor=color, facecolor='none')\n        ax.add_patch(rect)\n        \n        # Add label text using class label from dictionary\n        label_text = class_dict[int(class_id)]\n        ax.text(x1, y1, label_text, color='white', verticalalignment='top', bbox={'color': color, 'pad': 0})\n    \n    plt.show()\n\ndef main(image_path, bounding_box_path, class_dict):\n    # Read image\n    image = cv2.imread(image_path)\n    \n    # Read bounding boxes\n    with open(bounding_box_path, 'r') as file:\n        bounding_boxes = file.readlines()\n    \n    # Plot image with bounding boxes\n    plot_image_with_bounding_box(image, bounding_boxes, class_dict)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"yy[0], label_files[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dict_ = dict(zip(df_yolo['class_id'], df_yolo['class_name']))\nprint(dict_)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_no = 44\nmain(yy[img_no], label_files[img_no], class_dict = dict_)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_no = 45\nmain(yy[img_no], label_files[img_no], class_dict = dict_)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### In the Second Part, We Will Perform Image Analysis and Download All the Images and Text FilesÂ¶","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## PART--2) .  YOLO-IMPLEMENTATION:--------","metadata":{}},{"cell_type":"code","source":"label_files[0], yy[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##  correct label_text_files, and Image_files","metadata":{}},{"cell_type":"code","source":"print(\"first 3 label_files :->\", label_files[:3])\n\nimage_files = []\nfor label in label_files:\n    label_name = label.split('/')[-1].split('.')[0]\n    image_files.extend([i for i in yy if label_name in i])\n    \nprint(\"-\"*90)\nprint(\"first 3 image_files\", image_files[:3])\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame(list(zip(label_files, image_files)), columns=['label_files', 'image_files'])\nprint(df.shape)\ndf.head(2)\n\n## Now We have correct the label of the image files and label files ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"THis df Is The Actual train_data , Now from  this we will create train(90%) and valid(10%)","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ndf_train, df_valid = train_test_split(df, test_size = 19 , random_state = 42)\nprint(\"shape of df_train\", df_train.shape)\nprint(\"shape of df_valid\", df_valid.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Cloning Yolo V9 From Github","metadata":{}},{"cell_type":"code","source":"import os\nHOME = \"/kaggle/working/\"  ## Get The Current Working Directory \nprint(HOME)\nos.chdir(HOME)\n\n## Git Clone Yolo V9 \n\n!git clone https://github.com/SkalskiP/yolov9.git\n%cd yolov9\n!pip install -r requirements.txt -q","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Downloading Model Weights ","metadata":{}},{"cell_type":"code","source":"!wget -P {HOME}/weights -q https://github.com/WongKinYiu/yolov9/releases/download/v0.1/yolov9-c.pt\n!wget -P {HOME}/weights -q https://github.com/WongKinYiu/yolov9/releases/download/v0.1/yolov9-e.pt\n!wget -P {HOME}/weights -q https://github.com/WongKinYiu/yolov9/releases/download/v0.1/gelan-c.pt\n!wget -P {HOME}/weights -q https://github.com/WongKinYiu/yolov9/releases/download/v0.1/gelan-e.pt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Now We Will Create dataset folder ","metadata":{}},{"cell_type":"code","source":"cwd = \"/kaggle/working/\"\ndata_train_images = cwd+\"data/train/images\"\ndata_train_labels = cwd+\"data/train/labels\"\n\ndata_valid_images = cwd+\"data/valid/images\"\ndata_valid_labels = cwd+\"data/valid/labels/\"\n\nos.makedirs(data_train_images, exist_ok = True)\nos.makedirs(data_train_labels, exist_ok = True)\n\nos.makedirs(data_valid_images, exist_ok = True)\nos.makedirs(data_valid_labels, exist_ok = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_valid.head(1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" Now We have Created data folder","metadata":{}},{"cell_type":"markdown","source":"#### creating dataset folder which will  contain all images and the label  i.e train , valid","metadata":{}},{"cell_type":"code","source":"import os\nimport shutil\n\n# Creating directories for train and validation images and labels\nos.makedirs(\"/kaggle/working/dataset/train/images\", exist_ok=True)\nos.makedirs(\"/kaggle/working/dataset/valid/images\", exist_ok=True)\nos.makedirs(\"/kaggle/working/dataset/train/labels\", exist_ok=True)\nos.makedirs(\"/kaggle/working/dataset/valid/labels\", exist_ok=True)\n\n# Copying train images\nprint(\"COPYING TRAIN IMAGES :-->\", \"-\"*50)\nfor img_path in df_train['image_files']:\n    shutil.move(img_path, \"/kaggle/working/dataset/train/images\")\n\n# Copying validation images\nprint(\"COPYING VALID IMAGES :-->\", \"-\"*50)\nfor img_path in df_valid['image_files']:\n    shutil.move(img_path, \"/kaggle/working/dataset/valid/images\")\n\n# Copying train labels\nprint(\"COPYING TRAIN LABELS :-->\", \"-\"*50)\nfor label_path in df_train['label_files']:\n    shutil.move(label_path, \"/kaggle/working/dataset/train/labels\")\n\n# Copying validation labels\nprint(\"COPYING VALID LABELS :-->\", \"-\"*50)\nfor label_path in df_valid['label_files']:\n    shutil.move(label_path, \"/kaggle/working/dataset/valid/labels\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Counting the number of train labels\ntrain_label_count = len(glob.glob('/kaggle/working/dataset/train/labels/*'))\nprint(\"Number of train labels:\", train_label_count)\n\n# Counting the number of train images\ntrain_image_count = len(glob.glob('/kaggle/working/dataset/train/images/*'))\nprint(\"Number of train images:\", train_image_count)\n\n# Counting the number of valid labels\nvalid_label_count = len(glob.glob('/kaggle/working/dataset/valid/labels/*'))\nprint(\"Number of valid labels:\", valid_label_count)\n\n# Counting the number of valid images\nvalid_image_count = len(glob.glob('/kaggle/working/dataset/valid/images/*'))\nprint(\"Number of valid images:\", valid_image_count)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Deleting chest_detection \n! rm -rf /kaggle/working/chest_detection","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Moove Our dataset Folder  to Yolo Folder","metadata":{}},{"cell_type":"code","source":"! rm -rf /kaggle/working/yolov9/dataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shutil\n\n# Move the dataset folder to the Yolo folder\ndataset_dir = \"/kaggle/working/dataset\"\nyolo_dir = \"/kaggle/working/yolov9\"\nshutil.move(dataset_dir, yolo_dir)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Modify Yaml Code  :----->","metadata":{}},{"cell_type":"code","source":"list(dict_.values())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"yaml_dir = \"/kaggle/working/yolov9/dataset\"\nprint(\"Yaml Directory Is :--->\", yaml_dir)\nimport yaml\n\n# Data to write to YAML file\ndata = {\n    'names': list(dict_.values()),\n    'nc': len(list(dict_.values())),\n\n    'train': 'dataset/train/images/',\n    'val': 'dataset/valid/images/'\n}\n\n# Write data to YAML file\nwith open(yaml_dir+'/data.yaml', 'w') as file:\n    yaml.dump(data, file)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# with open(glob.glob('/kaggle/working/yolov9/dataset/train/labels/*')[0]) as f:\n#     file = f.read()\n#     print(file)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# glob.glob(\"/kaggle/working/yolov9/dataset/train/images/*\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training Custom Model ","metadata":{}},{"cell_type":"code","source":"%cd /kaggle/working/yolov9\n\n!python train.py \\\n--batch 16 --epochs 30 --img 640 --device 0 --min-items 0 --close-mosaic 15 \\\n--data /kaggle/working/yolov9/dataset/data.yaml \\\n--weights {HOME}/weights/gelan-c.pt \\\n--cfg models/detect/gelan-c.yaml \\\n--hyp hyp.scratch-high.yaml","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Examine The Training Result:-->","metadata":{}},{"cell_type":"code","source":"!ls {HOME}/yolov9/runs/train/exp/","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import Image\n\nImage(filename=f\"{HOME}/yolov9/runs/train/exp/results.png\", width=700)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import Image\n\nImage(filename=f\"{HOME}/yolov9/runs/train/exp/confusion_matrix.png\", width=1000)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import Image\n\nImage(filename=f\"{HOME}/yolov9/runs/train/exp/val_batch0_pred.jpg\", width=1000)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Now We Will Validate Our Custom Model :--->","metadata":{}},{"cell_type":"code","source":"%cd /kaggle/working/yolov9\n\n\n!python val.py \\\n--img 640 --batch 8 --conf 0.001 --iou 0.7 --device 0 \\\n--data /kaggle/working/yolov9/dataset/data.yaml \\\n--weights {HOME}/yolov9/runs/train/exp/weights/best.pt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### With Custom Model \n\nHere we will give the test data image path ","metadata":{}},{"cell_type":"code","source":"glob.glob(\"runs/val/*\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Examine the validation data ","metadata":{}},{"cell_type":"code","source":"!ls {HOME}/yolov9/runs/val/exp/","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import Image\n\nImage(filename=f\"{HOME}/yolov9/runs/val/exp/R_curve.png\", width=700)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import Image\n\nImage(filename=f\"{HOME}/yolov9/runs/val/exp/val_batch0_pred.jpg\", width=700)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}